Summary,Issue Type,Description,Priority,Story Points,Epic Link
"[US-01] 화면 캡처 기능",Story,"As a 시스템
I want to 게임 화면을 실시간으로 캡처할 수 있도록
So that 장애물 위치를 분석할 수 있습니다

Acceptance Criteria:
- 초당 30프레임 이상 캡처 가능
- 게임 캔버스 영역만 정확히 추출
- 캡처 지연 시간 10ms 이하",High,5,"Phase 1: MVP - 기본 자동 플레이"
"[US-02] 이미지 전처리 기능",Story,"As a 시스템
I want to 캡처된 이미지를 전처리할 수 있도록
So that 장애물 탐지 정확도를 높일 수 있습니다

Acceptance Criteria:
- 컬러 → 흑백 변환 구현
- 노이즈 제거 필터 적용
- 윤곽선(Edge) 추출 기능",High,3,"Phase 1: MVP - 기본 자동 플레이"
"[US-03] 기본 장애물 탐지",Story,"As a 시스템
I want to 선인장 장애물을 탐지할 수 있도록
So that 적절한 시점에 점프 명령을 내릴 수 있습니다

Acceptance Criteria:
- ROI(Region of Interest) 영역 설정
- 검은색 픽셀 감지 로직 구현
- 장애물과의 수평 거리 계산",High,5,"Phase 1: MVP - 기본 자동 플레이"
"[US-04] 키보드 입력 제어",Story,"As a 시스템
I want to 저지연 키보드 입력을 전송할 수 있도록
So that 정확한 타이밍에 공룡을 점프시킬 수 있습니다

Acceptance Criteria:
- PyDirectInput 기반 입력 시스템
- Space 키 점프 명령 구현
- 입력 지연 5ms 이하",High,3,"Phase 1: MVP - 기본 자동 플레이"
"[US-05] 익룡 탐지 기능",Story,"As a 시스템
I want to 익룡(Pterodactyl)을 탐지할 수 있도록
So that 높이에 따라 점프 또는 숙기를 결정할 수 있습니다

Acceptance Criteria:
- 익룡 형태 패턴 인식
- 높이별 익룡 분류 (상단/중단/하단)
- 선인장과 익룡 구분 가능",High,8,"Phase 2: 고도화 - 정밀 탐지 및 보정"
"[US-06] 숙기(Duck) 기능",Story,"As a 시스템
I want to 하향 키(↓) 입력으로 숙기를 할 수 있도록
So that 높이가 높은 익룡을 피할 수 있습니다

Acceptance Criteria:
- Down Arrow 키 입력 구현
- 숙기 지속 시간 제어
- 점프 vs 숙기 결정 로직",High,5,"Phase 2: 고도화 - 정밀 탐지 및 보정"
"[US-07] 게임 속도 측정",Story,"As a 시스템
I want to 현재 게임 속도를 측정할 수 있도록
So that 반응 거리를 동적으로 조정할 수 있습니다

Acceptance Criteria:
- 프레임 간 장애물 이동 거리 계산
- 속도 추정 알고리즘 구현
- 속도 변화 트래킹",Medium,5,"Phase 2: 고도화 - 정밀 탐지 및 보정"
"[US-08] 동적 임계값 조정",Story,"As a 시스템
I want to 속도에 따라 반응 거리를 조정할 수 있도록
So that 빠른 속도에서도 정확한 타이밍에 반응할 수 있습니다

Acceptance Criteria:
- 속도-거리 매핑 함수 구현
- Search Window 동적 확장
- 점프 타이밍 보정 로직",Medium,5,"Phase 2: 고도화 - 정밀 탐지 및 보정"
"[US-09] RL 환경 구축",Story,"As a 개발자
I want to OpenAI Gym 호환 환경을 구축할 수 있도록
So that 강화학습 에이전트를 학습시킬 수 있습니다

Acceptance Criteria:
- Gym 환경 클래스 구현 (reset, step, render)
- 상태 공간 정의 (observation space)
- 행동 공간 정의 (action space)
- 보상 함수 설계",Medium,8,"Phase 3: 지능화 - 강화학습 에이전트"
"[US-10] RL 에이전트 학습",Story,"As a 시스템
I want to PPO/DQN 알고리즘으로 에이전트를 학습할 수 있도록
So that 자율적으로 최적의 행동을 결정할 수 있습니다

Acceptance Criteria:
- Stable Baselines3 통합
- 학습 파이프라인 구축
- 하이퍼파라미터 튜닝
- 모델 저장/로드 기능",Medium,13,"Phase 3: 지능화 - 강화학습 에이전트"
"[US-11] 성능 평가 및 비교",Story,"As a 개발자
I want to 규칙 기반 vs RL 에이전트 성능을 비교할 수 있도록
So that 각 접근법의 장단점을 파악할 수 있습니다

Acceptance Criteria:
- 평가 메트릭 정의 (평균 점수, 최고 점수, 생존 시간)
- 자동화된 평가 스크립트
- 결과 시각화 및 리포트",Low,5,"Phase 3: 지능화 - 강화학습 에이전트"
